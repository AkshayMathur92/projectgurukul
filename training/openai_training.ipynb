{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import openai_utils\n",
    "import pandas as pd\n",
    "from projectgurukul import prompt_templates\n",
    "import json\n",
    "from llama_index.llms import ChatMessage, MessageRole\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>used_context</th>\n",
       "      <th>Final_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why does Vasishta refuse to give Sabala to Vis...</td>\n",
       "      <td>[\"sarga: 54\\nfile_path: data/ramayana/data/bal...</td>\n",
       "      <td>While Vasishta's refusal to give Sabala to Vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did Hanuman's devotion to Rama ever waver, eve...</td>\n",
       "      <td>[\"sarga: 13\\nfile_path: data/ramayana/data/sun...</td>\n",
       "      <td>Hanuman's devotion to Rama remained steadfast,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What drove Ravana to kidnap Sita, and was it s...</td>\n",
       "      <td>[\"sarga: 55\\nfile_path: data/ramayana/data/ara...</td>\n",
       "      <td>Ravana's abduction of Sita was primarily drive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe Bharata's character and his approach ...</td>\n",
       "      <td>[\"sarga: 16\\nfile_path: data/ramayana/data/ara...</td>\n",
       "      <td>**Character:**\\n\\nBharata is depicted as a vir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How did Ravana react upon learning about Dhumr...</td>\n",
       "      <td>[\"sarga: 51\\nfile_path: data/ramayana/data/yud...</td>\n",
       "      <td>The provided context does not provide details ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Why does Vasishta refuse to give Sabala to Vis...   \n",
       "1  Did Hanuman's devotion to Rama ever waver, eve...   \n",
       "2  What drove Ravana to kidnap Sita, and was it s...   \n",
       "3  Describe Bharata's character and his approach ...   \n",
       "4  How did Ravana react upon learning about Dhumr...   \n",
       "\n",
       "                                        used_context  \\\n",
       "0  [\"sarga: 54\\nfile_path: data/ramayana/data/bal...   \n",
       "1  [\"sarga: 13\\nfile_path: data/ramayana/data/sun...   \n",
       "2  [\"sarga: 55\\nfile_path: data/ramayana/data/ara...   \n",
       "3  [\"sarga: 16\\nfile_path: data/ramayana/data/ara...   \n",
       "4  [\"sarga: 51\\nfile_path: data/ramayana/data/yud...   \n",
       "\n",
       "                                         Final_label  \n",
       "0  While Vasishta's refusal to give Sabala to Vis...  \n",
       "1  Hanuman's devotion to Rama remained steadfast,...  \n",
       "2  Ravana's abduction of Sita was primarily drive...  \n",
       "3  **Character:**\\n\\nBharata is depicted as a vir...  \n",
       "4  The provided context does not provide details ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_csv(\"./Gurukul Data - data_labelled.csv\")\n",
    "train_df = all_df[all_df.Split == \"Train\"][[\"Question\", \"used_context\", \"Final_label\"]]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"context_str\"] = train_df.used_context.apply(\n",
    "    lambda contexts: \"\\n\\n\".join(json.loads(contexts))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_example(row):\n",
    "    chat_messages = prompt_templates.training_text_qa_template.format_messages(\n",
    "        query_str = row.Question,context_str= row.context_str)\n",
    "    chat_messages.append(\n",
    "        ChatMessage(\n",
    "            role=MessageRole.ASSISTANT,\n",
    "            content=row.Final_label\n",
    "        )\n",
    "    )\n",
    "    messages = openai_utils.to_openai_message_dicts(chat_messages)\n",
    "    return {\"messages\":messages}\n",
    "\n",
    "train_df[\"open_ai_examples\"] = train_df.apply(get_example, axis = 1)\n",
    "messages = [json.dumps(m, ensure_ascii=False) for m in train_df[\"open_ai_examples\"]]\n",
    "len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"openai_input.jsonl\"\n",
    "with open(FILE_NAME, \"w\") as f:\n",
    "    for message in messages:\n",
    "        f.write(message)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open(FILE_NAME, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-0JYtMd5VLwtO8fElt5Q3bKpM', bytes=560135, created_at=1705849148, filename='openai_input.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.fine_tuning.fine_tuning_job import Hyperparameters\n",
    "client = OpenAI()\n",
    "\n",
    "client.files.create(\n",
    "  file=open(FILE_NAME, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-AD07tu8yAlazKOE98zRwsYHY', created_at=1705849245, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-H3gA3aIB39O3UI9PxCnRxxWD', result_files=[], status='validating_files', trained_tokens=None, training_file='file-0JYtMd5VLwtO8fElt5Q3bKpM', validation_file=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-0JYtMd5VLwtO8fElt5Q3bKpM\", \n",
    "  model=\"gpt-3.5-turbo-1106\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n"
     ]
    }
   ],
   "source": [
    "print(messages[0]['role'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-AD07tu8yAlazKOE98zRwsYHY', created_at=1705849245, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-H3gA3aIB39O3UI9PxCnRxxWD', result_files=[], status='running', trained_tokens=None, training_file='file-0JYtMd5VLwtO8fElt5Q3bKpM', validation_file=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-AD07tu8yAlazKOE98zRwsYHY', created_at=1705849245, error=None, fine_tuned_model='ft:gpt-3.5-turbo-1106:macro-mate::8jTl73oZ', finished_at=1705849845, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-1106', object='fine_tuning.job', organization_id='org-H3gA3aIB39O3UI9PxCnRxxWD', result_files=['file-V5Yh4ovNAdS03xiE6HaKasHv'], status='succeeded', trained_tokens=479898, training_file='file-0JYtMd5VLwtO8fElt5Q3bKpM', validation_file=None)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "job = client.fine_tuning.jobs.retrieve(\"ftjob-AD07tu8yAlazKOE98zRwsYHY\")\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{'step': 151, 'train_loss': 0.5254576802253723, 'train_mean_token_accuracy': 0.8252595067024231}\n",
      "{'step': 141, 'train_loss': 0.5257101655006409, 'train_mean_token_accuracy': 0.8579465746879578}\n",
      "{'step': 131, 'train_loss': 0.8190422654151917, 'train_mean_token_accuracy': 0.7857142686843872}\n",
      "{'step': 121, 'train_loss': 0.3676629960536957, 'train_mean_token_accuracy': 0.8921568393707275}\n",
      "{'step': 111, 'train_loss': 0.44338780641555786, 'train_mean_token_accuracy': 0.862500011920929}\n",
      "{'step': 101, 'train_loss': 0.34354105591773987, 'train_mean_token_accuracy': 0.8834951519966125}\n",
      "{'step': 91, 'train_loss': 1.0396333932876587, 'train_mean_token_accuracy': 0.7714285850524902}\n",
      "{'step': 81, 'train_loss': 1.409155011177063, 'train_mean_token_accuracy': 0.6800000071525574}\n",
      "{'step': 71, 'train_loss': 0.21233804523944855, 'train_mean_token_accuracy': 0.9389401078224182}\n",
      "{'step': 61, 'train_loss': 0.3999319076538086, 'train_mean_token_accuracy': 0.8715789318084717}\n",
      "{'step': 51, 'train_loss': 0.3261723220348358, 'train_mean_token_accuracy': 0.8959107995033264}\n",
      "{'step': 41, 'train_loss': 0.435062438249588, 'train_mean_token_accuracy': 0.8940397500991821}\n",
      "{'step': 31, 'train_loss': 1.0613205432891846, 'train_mean_token_accuracy': 0.686274528503418}\n",
      "{'step': 21, 'train_loss': 0.5996552109718323, 'train_mean_token_accuracy': 0.8224755525588989}\n",
      "{'step': 11, 'train_loss': 0.4763445556163788, 'train_mean_token_accuracy': 0.8806451559066772}\n",
      "{'step': 1, 'train_loss': 0.8194189667701721, 'train_mean_token_accuracy': 0.7961309552192688}\n",
      "None\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# List up to 10 events from a fine-tuning job\n",
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-AD07tu8yAlazKOE98zRwsYHY\", limit=20)\n",
    "for d in events.data:\n",
    "    print (d.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gurukul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
